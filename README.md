# Sentiment-Aware Chatbot  
_FastAPI â€¢ LangChain â€¢ Mistral-7B (Ollama) â€¢ Streamlit_

A privacy-first chatbot that **remembers the conversation** and **adjusts its tone** to the
userâ€™s emotion on the fly.

---

## âœ¨ Features

| Capability           | Notes |
|----------------------|-------|
| **Local LLM**        | Runs Mistral-7B through **Ollama** â€“ no cloud, no data leaks |
| **Context Memory**   | `ConversationBufferMemory` keyed by `session_id` |
| **Sentiment**        | Default **VADER** (CPU-friendly) â€“ switch to HF `distilbert-sst2` in one line |
| **API**              | **FastAPI** with auto-generated OpenAPI 3.1 docs (`/docs`) |
| **UI**               | One-file **Streamlit** chat (optional) |
| **Tests**            | Tiny **pytest** smoke test keeps you safe from regressions |

---

## ğŸ—‚ Folder Layout

```
sentiment_chatbot/
â”‚  README.md
â”‚  requirements.txt
â”‚  streamlit_app.py      â† optional web UI
â”‚  .env                  â† secrets (optional)
â””â”€ app/
   â”œâ”€ __init__.py
   â”œâ”€ main.py            â† FastAPI entry-point
   â”œâ”€ chat.py            â† LLM call + sentiment + memory
   â”œâ”€ memory.py          â† memory helpers
   â”œâ”€ sentiment.py       â† sentiment detectors
   â””â”€ schemas.py         â† Pydantic models
â””â”€ tests/
   â””â”€ test_chat.py       â† basic unit test
```

---

## ğŸ”§ Prerequisites

* **Python 3.10+**  
* **Ollama** â‰¥ 0.1.34 (adds the `ollama` CLI)  
* ~6 GB free RAM and 4 GB disk for the model

---

## ğŸš€ Quick-Start

```powershell
# 1 â€” clone / move into empty dir
mkdir sentiment_chatbot && cd sentiment_chatbot

# 2 â€” create & activate virtual-env  (Windows PowerShell)
python -m venv .venv
.\.venv\Scripts\Activate.ps1

# 3 â€” install deps
pip install --upgrade pip
pip install -r requirements.txt   # or paste the list from this repo

# 4 â€” pull the LLM
ollama pull mistral

# 5 â€” run backend
uvicorn app.main:app --reload     # http://127.0.0.1:8000/docs

# 6 â€” run UI  (new terminal, same venv)
streamlit run streamlit_app.py    # http://localhost:8501
```

---

## ğŸ“ API Usage

### `POST /chat`

| Field        | Type   | Example                           |
|--------------|--------|-----------------------------------|
| `session_id` | string | `"user42"`                        |
| `message`    | string | `"I'm feeling down today"`        |

```bash
curl.exe -X POST http://127.0.0.1:8000/chat ^
         -H "Content-Type: application/json" ^
         -d "{ \"session_id\": \"user42\", \"message\": \"Hello\" }"
```

Successful 200 OK:

```jsonc
{
  "session_id": "user42",
  "answer": "Hi there! How can I help you today?",
  "sentiment": "NEUTRAL"
}
```

---

## ğŸ“ Architecture

```
[Browser / Streamlit]
        â”‚  POST /chat
        â–¼
  FastAPI  â”€â”€â–º SentimentDetector (VADER / HF)
        â”‚
        â”œâ”€â–º MemoryStore  (ConversationBufferMemory)
        â”‚
        â””â”€â–º ChatOllama â†’ Ollama â†’ Mistral-7B
```

---

## ğŸ›  Customisation

| Want toâ€¦ | Edit / Action |
|----------|---------------|
| Use faster/economy model | `app/chat.py` â†’ `ChatOllama(model="mistral:7b-instruct-q4_K_M")` |
| Swap sentiment engine    | Comment VADER, uncomment HF block in `app/sentiment.py` |
| Cap memory length        | Replace buffer with `SummaryMemory` or vector store |
| Production serve         | `uvicorn app.main:app --host 0.0.0.0 --port 8000 --workers 2` |
| Docker                   | Base `python:3.12-slim` + copy repo + install, **OR** mount hostâ€™s `/var/run/ollama.sock` |

---

## âœ… Testing

Why tests? They act as a smoke alarm when libraries change.

```bash
pip install pytest
pytest -q          # dots = green, letters = fail
```

`tests/test_chat.py` checks:

* `respond()` returns a non-empty string
* Sentiment label is one of POSITIVE/NEGATIVE/NEUTRAL

---

## ğŸ©¹ Troubleshooting

| Symptom | Fix |
|---------|-----|
| **`ModuleNotFoundError: ChatOllama`** | `pip install --upgrade langchain-community langchain-ollama` |
| FastAPI 500 + `"One input key expected"` | Ensure youâ€™re using the **manual message** `chat.py` (no `LLMChain`) |
| `curl` headers error in PowerShell | Use `curl.exe` or `Invoke-WebRequest` syntax |
| Streamlit works but Uvicorn restarts constantly | Keep `streamlit_app.py` **outside** the `app/` folder when using `--reload` |

---

## ğŸ“„ License

MIT Â© 2025 <Your Name>
