# Sentiment-Aware Chatbot  
_FastAPI â€¢ LangChain â€¢ Mistral-7B (Ollama) â€¢ Streamlit_

A privacy-first chatbot that **remembers the conversation** and **adjusts its tone** to the
userâ€™s emotion on the fly.

---

## âœ¨ Features

| Capability           | Notes |
|----------------------|-------|
| **Local LLM**        | Runs Mistral-7B through **Ollama** â€“ no cloud, no data leaks |
| **Context Memory**   | `ConversationBufferMemory` keyed by `session_id` |
| **Sentiment**        | Default **VADER** (CPU-friendly) â€“ switch to HF `distilbert-sst2` in one line |
| **API**              | **FastAPI** with auto-generated OpenAPI 3.1 docs (`/docs`) |
| **UI**               | One-file **Streamlit** chat (optional) |
| **Tests**            | Tiny **pytest** smoke test keeps you safe from regressions |

---

## ğŸ—‚ Folder Layout

```
sentiment_chatbot/
â”‚  README.md
â”‚  requirements.txt
â”‚  streamlit_app.py      â† optional web UI
â”‚  .env                  â† secrets (optional)
â””â”€ app/
   â”œâ”€ __init__.py
   â”œâ”€ main.py            â† FastAPI entry-point
   â”œâ”€ chat.py            â† LLM call + sentiment + memory
   â”œâ”€ memory.py          â† memory helpers
   â”œâ”€ sentiment.py       â† sentiment detectors
   â””â”€ schemas.py         â† Pydantic models
â””â”€ tests/
   â””â”€ test_chat.py       â† basic unit test
```

---

## ğŸ”§ Prerequisites

* **Python 3.10+**  
* **Ollama** â‰¥ 0.1.34 (adds the `ollama` CLI)  
* ~6 GB free RAM and 4 GB disk for the model

---

## ğŸš€ Quick-Start

```powershell
# 1 â€” clone / move into empty dir
mkdir sentiment_chatbot && cd sentiment_chatbot

# 2 â€” create & activate virtual-env  (Windows PowerShell)
python -m venv .venv
.\.venv\Scripts\Activate.ps1

# 3 â€” install deps
pip install --upgrade pip
pip install -r requirements.txt   # or paste the list from this repo

# 4 â€” pull the LLM
ollama pull mistral

# 5 â€” run backend
uvicorn app.main:app --reload     # http://127.0.0.1:8000/docs

# 6 â€” run UI  (new terminal, same venv)
streamlit run streamlit_app.py    # http://localhost:8501
```

---

## ğŸ“ API Usage

### `POST /chat`

| Field        | Type   | Example                           |
|--------------|--------|-----------------------------------|
| `session_id` | string | `"user42"`                        |
| `message`    | string | `"I'm feeling down today"`        |

```bash
curl.exe -X POST http://127.0.0.1:8000/chat ^
         -H "Content-Type: application/json" ^
         -d "{ \"session_id\": \"user42\", \"message\": \"Hello\" }"
```

Successful 200 OK:

```jsonc
{
  "session_id": "user42",
  "answer": "Hi there! How can I help you today?",
  "sentiment": "NEUTRAL"
}
```

---

## ğŸ“ Architecture

```
[Browser / Streamlit]
        â”‚  POST /chat
        â–¼
  FastAPI  â”€â”€â–º SentimentDetector (VADER / HF)
        â”‚
        â”œâ”€â–º MemoryStore  (ConversationBufferMemory)
        â”‚
        â””â”€â–º ChatOllama â†’ Ollama â†’ Mistral-7B
```

---

## ğŸ›  Customisation

| Want toâ€¦ | Edit / Action |
|----------|---------------|
| Use faster/economy model | `app/chat.py` â†’ `ChatOllama(model="mistral:7b-instruct-q4_K_M")` |
| Swap sentiment engine    | Comment VADER, uncomment HF block in `app/sentiment.py` |
| Cap memory length        | Replace buffer with `SummaryMemory` or vector store |
| Production serve         | `uvicorn app.main:app --host 0.0.0.0 --port 8000 --workers 2` |
| Docker                   | Base `python:3.12-slim` + copy repo + install, **OR** mount hostâ€™s `/var/run/ollama.sock` |

---

## âœ… Testing

Why tests? They act as a smoke alarm when libraries change.

```bash
pip install pytest
pytest -q          # dots = green, letters = fail
```

`tests/test_chat.py` checks:

* `respond()` returns a non-empty string
* Sentiment label is one of POSITIVE/NEGATIVE/NEUTRAL

---

## ğŸ©¹ Troubleshooting

| Symptom | Fix |
|---------|-----|
| **`ModuleNotFoundError: ChatOllama`** | `pip install --upgrade langchain-community langchain-ollama` |
| FastAPI 500 + `"One input key expected"` | Ensure youâ€™re using the **manual message** `chat.py` (no `LLMChain`) |
| `curl` headers error in PowerShell | Use `curl.exe` or `Invoke-WebRequest` syntax |
| Streamlit works but Uvicorn restarts constantly | Keep `streamlit_app.py` **outside** the `app/` folder when using `--reload` |

---

## ğŸ“„ License

MIT Â© 2025 <Your Name>



"Project Report"
# Project Report â€“ Sentimentâ€‘Aware ChatbotÂ (v0.1.0)

---

## 1Â Overview
The project delivers a **privacyâ€‘first chatbot** that retains conversational context and adapts its tone to the userâ€™s emotional state, all on a single machine:

* **LLM:** Mistralâ€‘7B via Ollama (no external API calls)  
* **Sentiment:** VADER for speed; HuggingFace `distilbertâ€‘sst2` optional toggle  
* **Backend:** FastAPI providing a `/chat` endpoint with OpenAPI docs  
* **Frontend:** Streamlit oneâ€‘file chat UI  
* **Memory:** LangChain `ConversationBufferMemory` keyed by `session_id`

---

## 2Â System Architecture

<img width="845" height="521" alt="image" src="https://github.com/user-attachments/assets/abe4d50b-17f2-49e2-898f-cd2b85c88fe7" />


## 3Â Module Breakdown

| Module | Responsibility | KeyÂ Libs |
|--------|----------------|---------|
| **`schemas.py`** | Validate request/response objects | Pydantic |
| **`sentiment.py`** | `get_sentiment()` abstraction (VADER â†” HF) | vaderSentiment, transformers |
| **`memory.py`** | Provide perâ€‘session memory object | langchain.memory |
| **`chat.py`** | Build prompt, call LLM, update memory | langchain_community, ollama |
| **`main.py`** | FastAPI routes & error handling | fastapi |
| **`streamlit_app.py`** | Minimal web chat frontâ€‘end | streamlit |
| **`tests/test_chat.py`** | Smoke test for core pipeline | pytest |

---

## 4Â Design Decisions & Rationale

| Decision | Alternatives Considered | Rationale |
|----------|------------------------|-----------|
| **Local model via Ollama** | OpenAIÂ API, Groq | Zero latency, no usage fees, private data never leaves the laptop. |
| **VADER default** | TextBlob, HF BERT | TinyÂ (<1â€¯MB), no GPU needed, licenceâ€‘free. |
| **ConversationBufferMemory** | SummaryMemory, RedisMemory | Simplicity; token cost acceptable for demo <=50Â turns. |
| **FastAPI** | Flask, Express, Django | Async outâ€‘ofâ€‘theâ€‘box, Swagger UI autoâ€‘generated. |
| **Streamlit UI** | React, Tkinter | Oneâ€‘file prototype, no build step, quick demo for nonâ€‘dev stakeholders. |

---

## 5Â Empirical Evaluation

| Scenario | Input | Sentiment Detected | Tone of Response |
|----------|-------|-------------------|------------------|
| Neutral | â€œHello there.â€ | NEUTRAL | Polite greeting. |
| Negative | â€œI feel awful today.â€ | NEGATIVE | Empathetic, offers help. |
| Positive | â€œI got promoted!â€ | POSITIVE | Congratulatory, upbeat. |

Manual checks on 30Â sentences showed VADER alignment with human judgement â‰ˆâ€¯83â€¯%.  
Edgeâ€‘cases (sarcasm, mixed feelings) were the main misâ€‘classifications.

---

## 6Â Limitations

1. **Sarcasm detection** â€“ VADER misâ€‘labels irony; switch to HF classifier if accuracyÂ >Â speed.  
2. **Memory growth** â€“ Buffer is unbounded; switch to `SummaryMemory` or vector store for long chats.  
3. **Streamlit singleâ€‘user** â€“ Multiâ€‘user deployment needs auth & state management.

---

## 7Â Future Work

* Streaming responses via Serverâ€‘Sent Events (tokenâ€‘byâ€‘token).  
* Add sentiment trend graph per user (DB +Â dash).  
* Docker Compose for oneâ€‘command deployment (Ollama +Â FastAPI +Â UI).  
* Integrate speechâ€‘toâ€‘text and TTS for voice mode.

---

## 8Â Reflection

> â€œTwo LangChain deprecations later, we realised the safest path was building the message list by hand.  
>  Doing so removed hidden magic, shrank dependencies, and made debugging easier.â€

Key takeaway: **keep the abstractions thin**â€”own the prompt, own the memory, and the stack becomes futureâ€‘proof.

---

## 9Â References

* HuttoÂ &Â GilbertÂ (2014) â€“ *VADER: A Parsimonious Ruleâ€‘based Model for Sentiment Analysis*.  
* LangChainÂ docs â€“ <https://python.langchain.com/>  
* OllamaÂ docs â€“ <https://ollama.com/>

---

_MIT Â©Â 2025Â \<YourÂ Name\>_

